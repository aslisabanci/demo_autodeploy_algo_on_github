{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import Algorithmia\n",
    "import json\n",
    "import os.path\n",
    "import joblib\n",
    "import xgboost\n",
    "import pandas as pd\n",
    "import hashlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Model file MD5 assertion done.\nModel object pipeline steps assertion done\nAll assertions are okay, we have a perfectly uploaded model!\n"
    }
   ],
   "source": [
    "#Github Action will convert this ipynb into a py file.\n",
    "\n",
    "client = Algorithmia.client()\n",
    "\n",
    "def load_model_config(config_rel_path=\"model_config.json\"):\n",
    "    \"\"\"Loads the model manifest file as a dict. \n",
    "    A manifest file has the following structure:\n",
    "    {\n",
    "      \"model_filepath\": Uploaded model path on Algorithmia data collection\n",
    "      \"model_md5_hash\": MD5 hash of the uploaded model file\n",
    "      \"model_origin_repo\": Model development repository having the Github CI workflow\n",
    "      \"model_origin_commit_SHA\": Commit SHA related to the trigger of the CI workflow\n",
    "      \"model_origin_commit_msg\": Commit message related to the trigger of the CI workflow\n",
    "      \"model_uploaded_utc\": UTC timestamp of the automated model upload\n",
    "    }\n",
    "    \"\"\"\n",
    "    config = []\n",
    "    config_path = \"{}/{}\".format(os.getcwd(), (config_rel_path))\n",
    "    if os.path.exists(config_path):\n",
    "        with open(config_path) as json_file:\n",
    "            config = json.load(json_file)\n",
    "    return config\n",
    "\n",
    "\n",
    "def load_model(config):\n",
    "    \"\"\"Loads the model object from the file at model_filepath key in config dict\"\"\"\n",
    "    model_path = config[\"model_filepath\"]\n",
    "    model_file = client.file(model_path).getFile().name\n",
    "    model_obj = joblib.load(model_file)\n",
    "    return model_file, model_obj\n",
    "\n",
    "def assert_model_md5(model_file):\n",
    "    \"\"\"\n",
    "    Calculates the loaded model file's MD5 and compares the actual file hash with the hash on the model manifest\n",
    "    \"\"\"\n",
    "    md5_hash = None\n",
    "    DIGEST_BLOCK_SIZE = 128 * 64\n",
    "    with open(model_file, \"rb\") as f:\n",
    "        hasher = hashlib.md5()\n",
    "        buf = f.read(DIGEST_BLOCK_SIZE)\n",
    "        while len(buf) > 0:\n",
    "            hasher.update(buf)\n",
    "            buf = f.read(DIGEST_BLOCK_SIZE)\n",
    "        md5_hash = hasher.hexdigest()\n",
    "    assert config[\"model_md5_hash\"] == md5_hash\n",
    "    print(\"Model file MD5 assertion done.\")\n",
    "    \n",
    "def assert_model_pipeline_steps(model_obj):\n",
    "    \"\"\"For demonstration purposes, asserts that the XGBoost model has the expected pipeline steps.\n",
    "    \"\"\"\n",
    "    assert model_obj.steps[0][0] == \"vect\"\n",
    "    assert model_obj.steps[1][0] == \"tfidf\"\n",
    "    assert model_obj.steps[2][0] == \"model\"\n",
    "    print(\"Model object pipeline steps assertion done\")\n",
    "\n",
    "\n",
    "config = load_model_config()\n",
    "xgb_path, xgb_obj = load_model(config)\n",
    "assert_model_md5(xgb_path)\n",
    "assert_model_pipeline_steps(xgb_obj)\n",
    "print(\"All assertions are okay, we have a perfectly uploaded model!\")\n",
    "\n",
    "\n",
    "# API calls will begin at the apply() method, with the request body passed as 'input'\n",
    "# For more details, see algorithmia.com/developers/algorithm-development/languages\n",
    "def apply(input):\n",
    "    series_input = pd.Series([input])\n",
    "    result = xgb_obj.predict(series_input)\n",
    "    return {\n",
    "        \"sentiment\": result.tolist()[0], \n",
    "        \"predicting_model_metadata\": {\n",
    "            \"model_file\": config[\"model_filepath\"],\n",
    "            \"origin_repo\": config[\"model_origin_repo\"], \n",
    "            \"origin_commit_SHA\": config[\"model_origin_commit_SHA\"], \n",
    "            \"origin_commit_msg\": config[\"model_origin_commit_msg\"]\n",
    "        }\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Calling algorithm apply() func with input: It was a\n{'sentiment': 1, 'predicting_model_metadata': {'model_file': 'asli/xgboost_automated/autodeployed_model_348410b2f7071377de060f030cca7d984b0f2dca.pkl', 'origin_repo': 'aslisabanci/demo_autodeploy_algo_on_algorithmia', 'origin_commit_SHA': '348410b2f7071377de060f030cca7d984b0f2dca', 'origin_commit_msg': 'Reverted multiple workflow testing'}}\n"
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    algo_input = \"It was a\"\n",
    "    print(f\"Calling algorithm apply() func with input: {algo_input}\")\n",
    "\n",
    "    algo_result = apply(algo_input)\n",
    "    print(algo_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}